{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bioe141A_ML_Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp4Oe25iPNgt",
        "colab_type": "text"
      },
      "source": [
        "# **Intro to Machine Learning**\n",
        "\n",
        "In this workshop, we will learn the basics of machine learning. We will start by trying basic annd standardized machine learning techniques with a toy example (part 1) followed by learning how to implement our custom neural networks (part 2). The goal of the workshop is to understand the simplicity of implementing machine learning.\n",
        "\n",
        "**Prerequisites**: Basic knowledge of Python and a basic overview of machine learning fundamentals (e.g., through pre-workshop prep work in conjunction with in-class lecture by Jan and Peter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onvwXnaa_PEZ",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: Basic machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aswCEjGdAo-Z",
        "colab_type": "text"
      },
      "source": [
        "When you are working with small data (such as small vectors and/or only a few training examples), standard machine learning approaches such as support vector machines (SVMs) and logistic regression are often sufficient to solve your problem. Fortunately, Python comes with a convenient library called `scikit-learn` which makes it ridiculously easy to implement basic machine learning techniques. Let's say you have the following training data, which we randomly generate in only 2 lines of code using one of the convenient `scikit-learn` generator functions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb-H0ZYtBqm3",
        "colab_type": "code",
        "outputId": "fff3bf6e-f463-4df1-f23e-9edf4126680c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Generate our training data.\n",
        "\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "X, y = make_blobs(n_samples=100, centers=3, n_features=2)\n",
        "\n",
        "print('Input data: ')\n",
        "print(X)\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print('Predictive data: ')\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data: \n",
            "[[  7.20373987  -3.71189018]\n",
            " [  6.79367161  -1.98597899]\n",
            " [  6.74842922  -1.49444422]\n",
            " [  5.42243926  -1.14513222]\n",
            " [  9.7055844   -1.0900761 ]\n",
            " [  9.79315977  -2.56446374]\n",
            " [  1.0319485   -8.4111421 ]\n",
            " [ 10.24624641  -0.96590843]\n",
            " [ 10.95692693  -1.59463521]\n",
            " [  5.04084603  -1.30848123]\n",
            " [  3.36599439  -7.91673827]\n",
            " [  2.68842465 -10.09552183]\n",
            " [  2.17267065  -1.10548787]\n",
            " [  5.65592371  -2.84350992]\n",
            " [ 10.49587741  -2.03844519]\n",
            " [ 11.61657341  -3.1821537 ]\n",
            " [  7.85616126  -1.1132728 ]\n",
            " [  1.79133482 -10.3915578 ]\n",
            " [  7.50608275  -2.249433  ]\n",
            " [  3.94604353  -1.81888282]\n",
            " [  3.3696267  -10.21432077]\n",
            " [  4.52035743  -1.69873187]\n",
            " [  5.84308801  -3.73764232]\n",
            " [  3.3041451   -8.50053763]\n",
            " [  3.41665252  -7.71370928]\n",
            " [  5.93599542  -4.11981008]\n",
            " [  4.33332608  -2.93242992]\n",
            " [  8.09019651  -2.74684593]\n",
            " [  6.36092562  -1.71974839]\n",
            " [  8.63945077  -1.75730262]\n",
            " [ 10.09862642  -2.66804657]\n",
            " [  5.17285196  -2.17992767]\n",
            " [  9.47732694  -3.66712961]\n",
            " [  2.8093357   -6.42234997]\n",
            " [  4.14600244  -0.66962329]\n",
            " [ 10.65584857  -0.78033978]\n",
            " [  5.38816621  -0.9350871 ]\n",
            " [  2.03941064  -9.64410241]\n",
            " [  1.56345467  -8.56737301]\n",
            " [  2.48855864  -7.76429857]\n",
            " [ 11.43525032  -1.43767624]\n",
            " [  2.860329    -8.80152698]\n",
            " [  7.96971788  -2.60991526]\n",
            " [  9.62614865  -2.0184325 ]\n",
            " [ 10.01442203  -3.91149017]\n",
            " [  4.18294818  -9.17708931]\n",
            " [  5.180028    -3.84568768]\n",
            " [  2.58681709  -8.23290891]\n",
            " [ 10.26619139  -2.47438783]\n",
            " [  3.34921555  -8.50447927]\n",
            " [  1.64162011  -7.64704511]\n",
            " [  8.57891085   0.52716744]\n",
            " [  9.87839855  -3.33497088]\n",
            " [  4.24862049  -0.24705622]\n",
            " [  1.83060644 -11.19948028]\n",
            " [ 10.17026613  -2.92401303]\n",
            " [  0.97759204  -8.25379749]\n",
            " [  5.79036959  -2.35446091]\n",
            " [  6.09613846  -1.43959341]\n",
            " [  0.66938593  -8.60103233]\n",
            " [  3.13248208  -5.57447196]\n",
            " [  2.93534403  -9.39407195]\n",
            " [  2.972073    -9.46402615]\n",
            " [  3.38836086  -1.46715566]\n",
            " [  4.66288485  -8.20532934]\n",
            " [  9.66251636  -3.721639  ]\n",
            " [  4.62007938  -2.94414032]\n",
            " [  3.96627251   0.5080538 ]\n",
            " [  7.51032651  -1.35946072]\n",
            " [ 11.14088425  -2.38517862]\n",
            " [  6.59074224  -2.17379515]\n",
            " [ 10.15573087  -3.10968163]\n",
            " [  2.55640657  -8.7397493 ]\n",
            " [  1.60396294 -10.9139205 ]\n",
            " [  6.67494696  -1.24994235]\n",
            " [  2.86333872  -8.59899268]\n",
            " [  4.54810999   0.03970749]\n",
            " [ 10.3355199   -3.82037478]\n",
            " [  5.24814739  -2.7373602 ]\n",
            " [  1.59978764  -7.92653047]\n",
            " [  4.1980839   -8.82929781]\n",
            " [ 10.37306808  -3.96674162]\n",
            " [  8.95591134  -1.84296337]\n",
            " [  9.84500287  -2.80136189]\n",
            " [ 10.18145518  -2.85169527]\n",
            " [  8.88088719  -5.2445315 ]\n",
            " [  0.5355213   -7.20542721]\n",
            " [ 10.62037698  -3.16339734]\n",
            " [  1.94171969  -9.42418906]\n",
            " [  9.18389237  -0.99257248]\n",
            " [  5.08340627  -2.23209358]\n",
            " [  1.71710595  -9.96267138]\n",
            " [  5.7475651   -4.1188375 ]\n",
            " [  3.66201295  -9.17590809]\n",
            " [  5.77158294  -1.5115245 ]\n",
            " [  2.32517752  -8.15106734]\n",
            " [  9.29454529  -2.67258133]\n",
            " [  9.66569182  -2.86778614]\n",
            " [ 11.16304887  -2.8156859 ]\n",
            " [  9.71614195  -3.84780547]]\n",
            "\n",
            "\n",
            "\n",
            "Predictive data: \n",
            "[0 0 0 0 2 2 1 2 2 0 1 1 0 0 2 2 2 1 0 0 1 0 0 1 1 0 0 2 0 2 2 0 2 1 0 2 0\n",
            " 1 1 1 2 1 0 2 2 1 0 1 2 1 1 0 2 0 1 2 1 0 0 1 1 1 1 0 1 2 0 0 0 2 0 2 1 1\n",
            " 0 1 0 2 0 1 1 2 2 2 2 2 1 2 1 2 0 1 0 1 0 1 2 2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VAMWOmZGIKL",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize the data on a plot. The first component of each input x vector is plotted on the x-axis while the second component of each input x vector is plotted on the y-axis. The dots are colored by their y-value (or \"class\"). The goal of machine learning is to predict the class from the input X vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFwS2EIZFMCC",
        "colab_type": "code",
        "outputId": "aca04f69-b297-4b01-be87-d17c6dcc101f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
        "colors = {0:'red', 1:'blue', 2:'green'}\n",
        "fig, ax = plt.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8pLk7GgHEqi",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1:** Let's say you trained your machine learning model with the above \"training data\". If you were given a new point (0, 0) and wanted to predict its class, which class would you predict based on the plot above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHwF_-oJCbRZ",
        "colab_type": "text"
      },
      "source": [
        "Let's say we want to predict the class (0, 1, or 2) based on a 2 element X vector. We can use any machine learning method we want to predict the class from any arbitrary x input vector. First, let's try one technique, the Support Vector Machine (SVM), for this task. The code to train the model is literally this easy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M90ZfmQFCpY6",
        "colab_type": "code",
        "outputId": "d87bce5b-c38b-4d15-b981-76481f8e84cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(gamma='scale')\n",
        "clf.fit(X, y) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oTfB7BfER-4",
        "colab_type": "text"
      },
      "source": [
        "Now, we can predict the output given a test input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L09EejPjEcAg",
        "colab_type": "code",
        "outputId": "cd35798a-9847-4a47-e3b5-0039fec15439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.predict([[10, -2]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1qMQub7Ejem",
        "colab_type": "text"
      },
      "source": [
        "Yay! Given a dataset, we were able to \"do machine learning\" in only 3 lines of code! You can also predict the class of multiple vectors at once:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjeykvf4ExhI",
        "colab_type": "code",
        "outputId": "8533335e-d0fb-4d2c-e6ad-9d406a3c3519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.predict([[-10.5, 2.3],\n",
        "             [3.5, -100.2],\n",
        "             [100, 101]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um_lZJLfHbtk",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2:** Do these predictions make sense based on the plot of the data? Why or why not? Test a few other input vectors that you predict the SVM will predict as 0, 1, and 2 (each)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ILVXGPKC4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shm6nltHHm-n",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 3:** Google the `scikit-learn` documentation to figure out how to implement logistric regression, linear regression, and decision tree classifiers. For all of these classifiers, predict the class of the same input vectors you used in Exercise 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQ1QK_vKGQY",
        "colab_type": "code",
        "outputId": "f8ae5fe0-12fa-4f22-b434-a07584035ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
        "clf.fit(X, y) \n",
        "clf.predict([[10, -2]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_a1xKrHJ-ZR",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 4:** Using the code for generating the sample dataset as a starting place, (1) generate a dataset with 5000 examples (instead of 100) and 50 features (instead of 2). Note that unlike when using training data with 2 dimensions, it is very difficult (or impossible) to visualize input data with 50 features (unless you use a family of techniques called \"dimensionality reduction\" which is beyond the scope of this workshop)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px_bCVWaKG-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9xI9j5SLBHW",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 5:** Split your training set above such that 80% are allocated for training and 20% are allocated for testing. Retrain using the 4 different classifiers. Based on the performance on the test set, which classifier performs the best?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzoboBWHLDvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL-TcxT8_WfT",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Neural Networks\n",
        "\n",
        "Sometimes, you have a lot of data from which you can train. Furthermore, these data may contain several features/complexities (like the 50-dimensional dataset you generated above). Fortunately, neural networks are able to scale appropriately to the size of the dataset and can handle arbitrarily big data in theory. As a result, deep learning has taken over as the go-to method for any BIG data problem.\n",
        "\n",
        "Note: If you are collecting your own datasets for this class, it is likely that your dataset will be much too small for a neural network. You have two options in this case: (1) use the simpler classifiers covered in Part 1 of this tutorial or (2) use techniques called \"data augmentation\" and \"transfer learning\" and then use a neural network (these techniques are beyond the scope of this workshop but ask the course staff if you need help implementing this).\n",
        "\n",
        "In this part of the workshop, we will predict handwritten digits from images. The inputs in this case are matrices representing the content of the corresponding image. We are using black and white images, where 0 indicates the color \"black\" and 1 indiicates the color \"white\".  The output in this case is a digit (0 through 9) representing the digit represented by the dataset.\n",
        "\n",
        "To \"do deep learning\", we will use a very convenient Python library called `keras`. Let's start by importing `keras`, which conveniently comes with a handwritten dataset loaded in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPvBbue9NxcI",
        "colab_type": "code",
        "outputId": "fca60bf8-a0d3-4d3e-ecef-e72b3d65d8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Import statements.\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.utils import np_utils, to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBPyzidWNrn0",
        "colab_type": "text"
      },
      "source": [
        "Now, let's load in the handwritten dataset (called \"MNIST\"):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udAowuS7O3pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocKDnFg3NxU1",
        "colab_type": "text"
      },
      "source": [
        "We can print the dataset to see that these greyscale image data are represented as matrices of 0s and 1s:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EZmWIfMO7El",
        "colab_type": "code",
        "outputId": "5157db16-3698-4ebd-c009-93e637919318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKQnSQgPN_CH",
        "colab_type": "text"
      },
      "source": [
        "Let's view some examples of the images in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgZkRcvMPI17",
        "colab_type": "code",
        "outputId": "9a7f7836-9f6c-470d-fd8f-25c60ab4a2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(y_train[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAELCAYAAABpiBWpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npEpVRCSi/wNP1hWWNT1twwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAELCAYAAABpiBWpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZRU1dX38e8GFUVEhhgVjaISA6Lg\nhFNQMcEJQUUjanCAqPhoHJM4xCkYBxwSnyAOGCecXomJEcTIqySiOOGUkCUgDhARBERUEAEhwnn+\nqN59u9ui6eo+VfdW9++zVi27bt26darZnt73jBZCQERE4miWdgFERBoTVaoiIhGpUhURiUiVqohI\nRKpURUQiUqUqIhJRyStVMxtpZlfGPlfKl2JCairnmLCY41TN7ENgc+AbYDUwHXgQ+GMIYU0Dr90L\neDiEsHUB7xkKXA6srHK4WwhhVkPKInWXwZgw4Abg9IpD9wCXBg3YLpmsxUSV924A/BvYpD7vd8XI\nVPuFEDYBtiUXvJcA9xbhc+rqTyGEVlUeqlBLL0sxMQQ4GugOdAP6AWemVJamLEsx4S4CPm3oRYp2\n+x9CWBJCeBI4HjjVzHYGMLNRZnatn2dmF5vZfDObZ2anm1kws05VzzWzjYHxQAcz+6ri0aFYZZfi\nyEhMnAr8PoQwN4TwMfB7YFDkryp1lJGYwMy2A04ChjX0OxW9TTWE8DowF9i/5mtmdhjwC6A30Ano\ntZZrLAMOB+ZVyTjnmVlPM1u8jiL0M7PPzWyamZ3VkO8icaQcE13J3eK5f1cckxRloJ4YAVwGrKj/\nt8gpVUfVPKBdnuMDgPtDCNNCCMuBoYVcNITwUgihTS2nPAZ0ATYDzgCuMrMTC/kMKZq0YqIVsKTK\n8yVAq4q2VklXKjFhZv2B5iGEJwq57tqUqlLdCvg8z/EOwJwqz+fkOafeQgjTQwjzQgirQwivAMOB\nn8T8DKm3VGIC+ApoXeV5a+ArdVRlQsljoqLJ4CbgvFjXLHqlamY9yP2yXsrz8nygai/b92q5VIyg\nD4AykpSlHBPTyHVSue4VxyRFKcbE94GOwItmtgD4K7ClmS0ws44FXgsoYqVqZq3NrC8wmtwQh7fz\nnPYYMNjMuphZS6C2sWafAO3NbNMCynCUmbW1nL3I/TUaW8DXkIiyEBPkhu78wsy2qujE+CUwqoD3\nS0QZiImp5CrpXSsep1dcY1fqmREXo1IdZ2ZLyRXocuAWYHC+E0MI44FbgYnAB8DkipdW5jl3BvAo\nMMvMFptZBzPb38y+qqUsJ1Rcdym5/5luDCE8UL+vJQ2QpZi4CxgHvE3uf6i/VRyT0spETIQQvgkh\nLPAHueaHNRXPV9fni0Ud/N9QZtaFXKC3CCF8k3Z5JH2KCakp6zGR+tx/M+tvZi3MrC1wIzAui78o\nKR3FhNRUTjGReqVKbjbLQmAmuSlrGksqigmpqWxiIlO3/yIi5S4LmaqISKOhSlVEJKL1CjnZzJpE\nW0EIQRME6qipxASwKISwWdqFKAdNPSaUqYrUzey0CyCZkzcmVKmKiESkSlVEJCJVqiIiEalSFRGJ\nSJWqiEhEqlRFRCIqaJyqSJbsscceAJxzzjkAnHLKKQA8+OCDAIwYMQKAf/7znymUTpoqZaoiIhEV\ntKBKKWZKNG/eHIBNN82/cLdnJS1btgTgBz/4AQA///nPAfjd734HwIknJvv7ff311wDccMMNAFx9\n9dW1lkEzquoujdkzu+66KwDPPfccAK1bt8573pIluf392rdvH+Nj3woh7BnjQo1dOcyo+vGPfwzA\nI488UnnswAMPBODdd9+t62XyxoQyVRGRiEreprrNNtsAsMEGGwCw3377AdCzZ08A2rTJ7SR77LHH\n1ul6c+fOBeDWW28FoH///gAsXbq08px//zu3zfsLL7zQoLJLuvbaay8AHn/8cSC5m/G7Lf83X7Vq\nFZBkqPvssw9QvW3Vz5HSO+CAA4Dk3+eJJ6LsDF2QHj16APDGG29Ev7YyVRGRiEqSqXobGCTtYGtr\nM62rNWvWAHDFFVcA8NVXuX29vI1k/vz5led+8cUXQEFtJZIB3m6+++67A/Dwww8DsOWWW+Y9//33\n3wfgpptuAmD06NEAvPzyy0ASKwDDhg0rQomlLnr16gXA97//faC0mWqzZrk8crvttgNg2223rXzN\nLE5XijJVEZGIVKmKiERUktv/jz76qPLnzz77DKj77f9rr70GwOLFiwE46KCDgKSj4aGHHopWTsmW\nu+66C6g+PK423kzQqlUrIOmY9NvNbt26RS6h1IdP0nj11VdL/tnedHTGGWcASZMSwIwZM6J8hjJV\nEZGISpKpfv7555U/X3TRRQD07dsXgH/9619AMiTKTZkyBYCDDz4YgGXLlgHQtWtXAM4///willjS\n5NNPjzjiCODbHQiegY4bNw5IJnzMmzcPSGLKOyh/9KMf5b2OpMM7i9Jwzz33VHvunZsxKVMVEYmo\n5IP/x4wZAyRDq3zAdvfu3QE47bTTgCT78AzVTZs2DYAhQ4YUv7BSUj70bsKECUAy/dQH948fPx5I\n2lh9WqEPlfIs5NNPPwWSSR8+/M4zX0jaX7XYSul4m/bmm2+eWhlq9uV4rMWkTFVEJKLUlv778ssv\nqz33xS+c98796U9/ApJsQxqfHXfcEUja2z2bWLRoEZBM5HjggQeAZKLH3/72t2r/XZeNNtqo8udf\n/vKXAAwcOLBBZZe669OnD1D936FUPDv2Qf/u448/jv5ZylRFRCLKzCLVQ4cOBZKeX28v6927NwDP\nPvtsKuWS4mjRokXlz95+7pmMt7P7eMY333wTiJvh+MI+Ujq+TKfz/pFS8BjzjPW9994Dqi+8FIsy\nVRGRiDKTqXovv7eleq/s3XffDcDEiROBJGu5/fbbgaRnWMrLbrvtVvmzZ6juqKOOArRUY2NXjGX3\nfMTIYYcdBsBJJ50EwCGHHFLtvGuuuQZIZmrGpExVRCSizGSqbubMmQAMGjQIgPvvvx+Ak08+udp/\nN954YyDZ5K3qUn+Sfbfcckvlzz7TyTPT2Bmqz+DRCJJsadeu3TrP8fHrHiPex7L11lsDyWL3PorD\n/61XrFgBJGuHrFy5EoD11stVeW+99VbDv8BaKFMVEYkoc5mq84VrfW6uZza+Ydf1118PJIvMXnfd\ndUBxxp1JPL7mQ9WFy71d/MknnyzKZ3qGWrX93deWkNLx7NH/HUaOHAnAZZddttb3+Cwsz1S/+eYb\nAJYvXw7A9OnTAbjvvvuApM/F73Y++eQTINl2yUeQxFqRKh9lqiIiEWU2U3VTp04FYMCAAQD069cP\nSNpazzzzTCDZmsFXtZJs8kzB28IAFi5cCCSz5xrKx8D62Gfn600A/PrXv47yWVJ3Z599NgCzZ88G\nkk0/a+NrMfuaIe+88w4AkydPrtNn+hohm222GQCzZs0qoMT1o0xVRCSizGeqzseT+Ur/viKR9+b5\ntre+yvvzzz9f2gJKvXnPbENHcHiG6qtW+VoC3p72+9//vvJcXz9ASu/GG28s2Wd5H4zz7c2LSZmq\niEhEmc9UvffvJz/5CQA9evQAkgzVeS/gpEmTSlg6iaGhvf4+ksAz0+OPPx6AsWPHAnDsscc26PrS\neJRiO2xlqiIiEWUuU/WVbM455xwAjjnmGAC22GKLvOevXr0aSNrjNGsm23y8YdX9oo4++mig8H3H\nLrzwQgCuvPJKIFmH9ZFHHgGSVa5ESkmZqohIRKlnqp6B+r5DnqF27Nix1vf5zAmfSVWs2TgSl8+m\nqTq7yWPAd9T12TGfffYZAPvssw+QrPvg88F9/rePZXzmmWcAuOOOO4r3BaQs+Z2R7zJR13Gu9aFM\nVUQkopJnqr7y9k477QTAbbfdBkDnzp1rfZ+vNnPzzTcDSc+u2lDLX/PmzYFkxo331vs+Zj5brqZX\nXnkFSNbaveqqq4paTilffmfkq1gVkzJVEZGIVKmKiERU1Nt/X4T2rrvuqjzmA7W33377Wt/rt3Y+\ntdA7IXz5MClPr776KlB9Kw2f0OG848qbipx3XI0ePRoofAiWyL777gvAqFGjivYZylRFRCKKmqnu\nvffeQDJdcK+99gJgq622Wud7fdFZH1bji1D7hoDSOPjiJj6pA5LlG30hlJqGDx8OwJ133gnABx98\nUMwiSiNUdbJJsSlTFRGJKGqm2r9//2r/zccXPnnqqaeAZHsEbzstxpaxkj1Vl/nzxaRrLiot0lDj\nx48H4LjjjivZZypTFRGJyKpOF1znyWZ1P7mMhRBK1wBT5ppKTABvhRD2TLsQ5aCpx4QyVRGRiFSp\niohEpEpVRCQiVaoiIhGpUhURiajQcaqLgNnFKEiGbJt2AcpMU4gJUFwUoknHREFDqkREpHa6/RcR\niUiVqohIRKpURUQiUqUqIhKRKlURkYhUqYqIRKRKVUQkIlWqIiIRqVIVEYlIlaqISESqVEVEIlKl\nKiISUckrVTMbaWZXxj5XypdiQmoq65gIIUR7AB8CK4ClwGLgFeB/gGYRrt0LmFvgew4CJgJLgA9j\nflc9yjYm2gAPAAsrHkPT/h01tUcGY+IiYGpFef4DXNSQMhQjU+0XQtiE3FqDNwCXAPcW4XPqYhlw\nH7lfmqQnSzHxv0BLoCOwF3CymQ1OqSxNWZZiwoBTgLbAYcA5ZnZCva9WhL9AvWsc2wtYA+xc8XwU\ncG2V1y8G5gPzgNOBAHSqei6wMbm/bGuAryoeHQooV2+UqabyyFpMkFtAuUeV55cBL6b9e2pKj6zF\nRJ7y3QqMqO/3K3qbagjhdWAusH/N18zsMOAX5Cq9TuRS93zXWAYcDswLIbSqeMwzs55mtrhohZei\nyEBMWI2fdy78W0hMGYgJ/yyrKMO0en0RStdRNQ9ol+f4AOD+EMK0EMJyYGghFw0hvBRCaBOhfFJ6\nacXE/wcuNbNNzKwT8DNyzQGSvizUE0PJ1Yv3F/IZVZWqUt0K+DzP8Q7AnCrP5+Q5RxqntGLiPHK3\niO8DY4FHyWVIkr5U6wkzO4dc2+oRIYSV9b1O0StVM+tB7pf1Up6X5wNbV3n+vVoupc20Gok0YyKE\n8HkIYWAIYYsQQldy/w+8Xuh1JK606wkz+xlwKfDjEEKD/sgWrVI1s9Zm1hcYDTwcQng7z2mPAYPN\nrIuZtQRqG2v2CdDezDYtoAzNzGxDYP3cU9vQzDYo4GtIRBmJiR3MrL2ZNTezw4Eh5Do5JAUZiYmB\nwPXAwSGEWQUUP69iVKrjzGwpuRT9cuAWIO+QlRDCeHI9bROBD4DJFS99K/UOIcwgd6s2y8wWm1kH\nM9vfzL6qpSwHkLvVexrYpuLnZ+v1raQhshQTewBvkxuTOAwYGEKod6eE1FuWYuJaoD3whpl9VfEY\nWd8vlqktqs2sC7lBuC1CCN+kXR5Jn2JCasp6TKQ+99/M+ptZCzNrC9wIjMviL0pKRzEhNZVTTKRe\nqQJnkpsuOBNYDZyVbnEkAxQTUlPZxESmbv9FRMpdFjJVEZFGQ5WqiEhE6xVyspk1ibaCEIKt+yyB\nphMTwKIQwmZpF6IcNPWYUKYqUjez0y6AZE7emFClKiISkSpVEZGIVKmKiESkSlVEJCJVqiIiEalS\nFRGJSJWqiEhEBQ3+z6IrrrgCgKuvvhqAZs1yfyd69epVec4LL7xQ8nKJSOltsskmALRq1QqAI444\nAoDNNsuN0b/lllsAWLmy3rulrJMyVRGRiMo2Ux00aBAAl1xyCQBr1qyp9rpW3xJp/Dp27Agk9cC+\n++4LwM475991fMsttwTgvPPOK1qZlKmKiERUtpnqtttuC8CGG26Yckmk2Pbee28ATjrpJAAOPPBA\nALp27VrtvF/96lcAzJs3D4CePXsC8PDDDwPw2muvFb+wUlSdO3cG4IILLgBg4MCBAGy00UYAmOXW\nQpozJ7eL9dKlSwHo0qULAAMGDADgjjvuAGDGjBnRy6hMVUQkIlWqIiIRld3tf+/evQE499xzqx33\nNL5v374AfPLJJ6UtmER3/PHHAzB8+HAAvvOd7wDJLd7zzz8PJMNlbr755mrv9/P89RNOOKG4BZbo\nNt10UwBuvPFGIIkJHzpV0/vvvw/AoYceCsD6668PJPWDx5D/txiUqYqIRFQ2map3Otx///1A8hfM\neZYye7bWEi5X662XC8c999wTgLvvvhuAli1bAjBp0iQArrnmGgBeeuklAFq0aAHAY489BsAhhxxS\n7bpvvvlmMYstRdS/f38ATj/99FrPmzlzJgAHH3wwkHRUderUqYily0+ZqohIRGWTqZ566qkAdOjQ\nodpxb1d78MEHS10kicyHTN1zzz3Vjk+YMAFI2tO+/PLLaq/78ZoZ6ty5cwF44IEH4hdWSuK4447L\ne/zDDz8E4I033gCSwf+eoTofSlVKylRFRCLKfKbqvXQ/+9nPgGQ66uLFiwG49tpr0ymYRONtpJdd\ndhmQTDH2Adq+aE7NDNVdfvnleY/7VMRPP/00XmGlpM444wwAhgwZAsCzzz4LwAcffADAwoULa33/\n5ptvXsTS5adMVUQkosxmqr5QwuOPP5739REjRgAwceLEUhVJIrrqqqsqf/YMddWqVQA888wzQNJO\ntmLFimrv9anJ3oa6zTbbAMm4VL97GTt2bFHKLqXjU46HDh1ar/f7AiulpExVRCSizGaqhx12GADd\nunWrdvwf//gHkMyykfLSpk0bAM4+++zKY96G6hnq0Ucfnfe9PubwkUceAWCPPfao9vpf/vIXAG66\n6aaIJZYs83bzjTfeOO/ru+yyS7Xnr7zyCgCvvvpq0cqkTFVEJKLMZaqepdxwww3VjvvsGR+vumTJ\nktIWTKLYYIMNgPxzrz3r+O53vwvA4MGDATjyyCOBZOFh3yrDM1z/ry/xt2zZsqKUXdLjs+p22mkn\nAH7zm98A0KdPn2rn+XZKNRet97ZZj6nVq1cXrazKVEVEIspMprqu3v5Zs2YBWn2q3HkPf9Wxo76K\n1H/+8x9g7VvheLbh41V9a4xFixYBMG7cuCKUWNLgq0vttttuQFIv+L+5jwjxmPA2Uu+L8czW+boS\nxxxzDJD0yXg8xqRMVUQkosxkqmvbwM/VbGOV8uQz4ar28D/11FMAtGvXDkhWHPJxpqNGjQLg888/\nB2D06NFAkrX4cylv3t4OScb517/+tdo5vhX9c889B8DLL78MJLHjx2tu/Od3Q8OGDQPgo48+AmDM\nmDGV58TatlqZqohIRKlnqrvuuivw7RWGnGcr7777bsnKJMVXdRM+zyLW5YADDgCSjf/8rsbb26U8\nefupZ6EAF110UbVzxo8fDyQzKf2Ox2Pn6aefBpJxqd5W6mOWPXM96qijgGSs89///vfKz/DdBb74\n4otqnz1lypSCvo8yVRGRiFLPVH3VmbZt21Y7PnnyZAAGDRpU6iJJRvk2xJ6h+igBtamWp+bNmwPJ\nKmW+xTgkY40vvfRSIPk39gzVd4e47bbbgGSUgO9RddZZZwHJ2iCtW7cGYL/99gOSra19DDQk6/Y6\nX5t1u+22K+h7KVMVEYnI1jYmMO/JZnU/uY58ZkPNXv9TTjkFgEcffTT2R65TCMFK/qFlqhgxsS4e\nMx67PgqgyOumvhVC2LOYH9BY1DUmPJv0dtLly5dXvlZz/dS9994bSGZEHX744UBy9/Lb3/4WSPaw\nq7kDwNqceOKJlT//9Kc/rfbahRdeCCRrt+aRNyaUqYqIRJRapup/UbzNtGamuv322wPp7I6qTLXu\nSpmp+l7u3tOrTDWb6hoT8+fPB5Ie/KrjRGfMmAEkq0+tbVdUX2fVx58Wc05/HspURUSKreS9/z4u\ntXfv3kCSofq4sttvvx3QHH/5Nr97kcZhwYIFQJKptmjRovK17t27VzvX704mTZoEJDOhfFfVEmeo\ntVKmKiISkSpVEZGISn7779tpbLHFFtWOf/zxx0D1AcAiVb344ovA2hcilvLi0459cZ3dd9+98jXf\nevq+++4DkqmjxViqLzZlqiIiEaU+TVWkrqZOnQokUxG942qHHXYAij6kSiJbunQpAA899FC1/5Y7\nZaoiIhGVPFP1Qb2+VWzPnj1LXQQpc9dffz0A99xzDwDXXXcdAOeeey4A06dPT6dgIihTFRGJKvUF\nVbJI01TrLo2Y8GXcHnvsMSCZSOJbb/iiG5G3qtY01TpqKvUEmqYqIlJ8ylTzUKZad2nGhGes3qbq\nS8l169YNiN62qky1jppKPYEyVRGR4lOmmocy1bprKjGBMtU6a+oxoUxVRCSiQsepLgJKv2p0aW2b\ndgHKTFOICVBcFKJJx0RBt/8iIlI73f6LiESkSlVEJCJVqiIiEalSFRGJSJWqiEhEqlRFRCJSpSoi\nEpEqVRGRiFSpiohEpEpVRCQiVaoiIhGpUhURiUiVqohIRCWvVM1spJldGftcKV+KCamprGMihBDt\nAXwIrACWAouBV4D/AZpFuHYvYG6B7zkImAgsAT6M+V31KNuYuBCYBXwJzAP+F1gv7d9TU3pkMCai\n1hPFyFT7hRA2IbeA6w3AJcC9RficulgG3AdclNLnS06WYuJJYPcQQmtgZ6A7cF5KZWnKshQTceuJ\nIvwF6l3j2F7AGmDniuejgGurvH4xMJ9c1nA6EIBOVc8FNib3l20N8FXFo0MB5eqNMtVUHlmNiYpr\ntQf+DtyR9u+pKT2yGhOx6omit6mGEF4H5gL713zNzA4DflHxZTqRS93zXWMZcDgwL4TQquIxz8x6\nmtniohVeiiLtmDCzn5rZl+S2/egO3NWQ7yMNl3ZMxFSqjqp5QLs8xwcA94cQpoUQlgNDC7loCOGl\nEEKbCOWT0kstJkII/y/kbv93BEYCnxTyGVI0jaKeKFWluhXweZ7jHYA5VZ7PyXOONE6px0QI4X1g\nGnBHsT5DCpJ6TMRQ9ErVzHqQ+2W9lOfl+cDWVZ5/r5ZLaYfCRiJjMbEesEOE60gDZCwmGqRolaqZ\ntTazvsBo4OEQwtt5TnsMGGxmXcysJVDbWLNPgPZmtmkBZWhmZhsC6+ee2oZmtkEBX0MiykhMnG5m\n3634eSfg18A/6vwlJKqMxETUeqIYleo4M1tKLkW/HLgFGJzvxBDCeOBWcmPEPgAmV7y0Ms+5M4BH\ngVlmttjMOpjZ/mb2VS1lOYBcb+DTwDYVPz9br28lDZGlmPgh8LaZLSMXF08Dl9Xva0kDZCkmotYT\nVjGUIBPMrAswFWgRQvgm7fJI+hQTUlPWYyL1uf9m1t/MWphZW+BGYFwWf1FSOooJqamcYiL1ShU4\nE1gIzARWA2elWxzJAMWE1FQ2MZGp238RkXKXhUxVRKTRUKUqIhLReoWcbGZNoq0ghGBpl6FcNJWY\nABaFEDZLuxDloKnHhDJVkbqZnXYBJHPyxoQqVRGRiFSpiohEpEpVRCQiVaoiIhGpUhURiaigIVWl\nMHz4cADOOy+3F9vUqVMB6Nu3LwCzZ6sTVkSyS5mqiEhEmclUO3bsCMBJJ50EwJo1awDo0qULAJ07\ndwaUqTYlO+64IwDrr78+AAcccAAAd9yR2/3EY2Rdxo4dC8AJJ5xQeWzVqlXRyiml5zGx3377AXD9\n9dcD8MMf/jC1MjllqiIiEWUmU/30008BmDRpEgBHHnlkmsWRFHTt2hWAQYMGAXDccccB0KxZ7m9/\nhw4dgCRDresKax5LI0eOrDx2wQUXAPDll182sNSShk03ze2WMnHiRAAWLFgAwBZbbFHteRqUqYqI\nRJSZTHXZsmWA2kybsmHDhgHQp0+folz/lFNOqfz53nvvBeDll18uymdJaXmGqkxVRKSRUaUqIhJR\nZm7/27RpA0D37t1TLomkZcKECcC3b/8XLlwIJLfs3nFVc0iVD6858MADi1pOyR6z7CyBrExVRCSi\nzGSqLVu2BGCbbbbJ+3qPHj0AmDFjBqAOrcbozjvvBGDMmDHVjv/3v/8F1t350Lp1ayCZ2uxDsFzV\n67755psNK6xkig+v23DDDVMuiTJVEZGoMpOpzps3D4BRo0YBMHTo0Gqv+/PFixcDcNttt5WqaFIi\n33zzDQBz5syp1/sPPfRQANq2bZv39blz51b+vHLlynp9hmTbnnvuCcDkyZNTK4MyVRGRiDKTqbpr\nrrkG+HamKrI2vlDKGWecAcBGG22U97yrrrqqZGWS4vK7miVLlgDJtNUddtghtTI5ZaoiIhFlLlN1\naxuLKDJw4EAALr30UgA6deoEJMvB1TRlyhQgGUUg5c/7Vl588UUgWcQ+C5SpiohElNlMtdDl3aT8\n+ULlJ598MgC9e/fOe17Pnj2BtceGL+fnmezTTz8NwIoVK6KVVWRtlKmKiESU2UxVmo6dd94ZgCef\nfBJY+6y6uvJ2tj/+8Y8NK5iUnfbt26ddBGWqIiIxKVOVzPCVhta14tC6RoZ4T/Dhhx8OwPjx42MV\nUTIuC9swKVMVEYkos5nq2rIR36ZYc/8bD19VqlevXkCyTfkzzzwDwNdff13r+0877TQAzj333CKV\nULLKN/7TOFURkUbKChkHamYlGzS6evVqYO1jEbt16wbA9OnTo392CCE7y4hnXCljYm183vdnn31W\n7Xi/fv2AaG2qb4UQ9oxxocaulDFx7LHHAvDnP/8ZSMYi77TTTkDR113OGxPKVEVEIspsm+rIkSMB\nOPPMM/O+PmTIEAAuuOCCkpVJssnXUZWmx1ercj5ypEWLFmkUB1CmKiISVWYzVd+LShoXX0nqkEMO\nqTz23HPPAYXPzR88eDAAw4cPj1Q6KTdjx44Fkvqic+fOQHIHe/bZZ5e8TMpURUQiymzvv3vvvfeA\nb6/o7eNYfS3NmTNnRvtM9f7XXV1jwleWuvzyywE4+OCDK1/bbrvtgHXvTdWuXTsA+vTpA8CIESMA\n2GSTTaqd5xmvz67xsYwNpN7/OkqjnvjDH/4AJHcvm2++ObDuMc4NpN5/EZFiy2ybqps2bRoA22+/\nfbXj2hGgvPgMOF+RqqqLL74YgKVLl9Z6Dc9ud999d+DbY5iff/55AO68804gWoYqZcRjYtWqVamV\nQZmqiEhEqlRFRCLK/O2/LzTsUw6l8TnrrLPq9b6FCxcCMG7cOADOP/98oOidE5JhrVu3BuCoo44C\n4Iknnih5GZSpiohElPlM1eJ/kN0AAAENSURBVBdMeeeddwDo0qVLmsWReho0aBCQLM936qmn1vm9\nPlxu+fLlwLe3S/GlA6XpGjBgAAArV64EkvoiDcpURUQiynym6kt37bLLLimXRBpiypQpQDJt8PXX\nX6987dprrwWgbdu2AIwZMwaACRMmAMlUxAULFpSmsFJ2Jk2aBCR3smluR65MVUQkosxPU02DpqnW\nXVOJCTRNtc6aekwoUxURiUiVqohIRKpURUQiUqUqIhKRKlURkYgKHae6CCjqnq8ZsG3aBSgzTSEm\nQHFRiCYdEwUNqRIRkdrp9l9EJCJVqiIiEalSFRGJSJWqiEhEqlRFRCJSpSoiEpEqVRGRiFSpiohE\npEpVRCSi/wNP1hWWNT1twwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8nYL-MnPMA7",
        "colab_type": "text"
      },
      "source": [
        "Lets view the \"shape\" of the training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opfPEL20PFPD",
        "colab_type": "code",
        "outputId": "6c01513d-85dc-432d-be15-8f1bbc499558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFDRfzyPHGm",
        "colab_type": "text"
      },
      "source": [
        "We see that the training set has 60,000 images and the testing set has 10,000 images. Each image is a matrix of 1s and 0s with dimensions 28x28 pixels.\n",
        "\n",
        "Let's start the process of putting these images into a neural network! In this case, we will use a standard [Multi-Layer Perceptron (MLP)](https://en.wikipedia.org/wiki/Multilayer_perceptron) network. As we see from [this image](http://rasbt.github.io/mlxtend/user_guide/classifier/NeuralNetMLP_files/neuralnet_mlp_1.png) of a MLP and as we recall from this workshop's lecture, MLP neural networks take a vector in as input. Therefore, let's \"flatten\" our 28x28 input matrices into a single vector (of size 28x28=784):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tStlTVZoPqAh",
        "colab_type": "code",
        "outputId": "b14c4ada-337b-46b6-816c-ed0cf7436dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Train matrix shape\", X_train.shape)\n",
        "print(\"Test matrix shape\", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train matrix shape (60000, 784)\n",
            "Test matrix shape (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAlCP473RVTy",
        "colab_type": "text"
      },
      "source": [
        "We should convert the y values to categorical variables (since that is what we are predicting):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HFn-zsyRUDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fYaZzoQ0Xj",
        "colab_type": "text"
      },
      "source": [
        "Let's build a very simple MLP network (sometimes called a \"Dense\" network because each node in any given layer is fully connected to every other node in this next layer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfhF1e3-PyXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation('relu'))                            \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jhiPviRAWn",
        "colab_type": "text"
      },
      "source": [
        "We always have to \"compile\" our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsU-RqAMP1cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K929f3bVRIDd",
        "colab_type": "text"
      },
      "source": [
        "Now, let's train the model. We specify the number of \"epochs\", which is the number of passes that are made through the input data during the network training process. We keep some of the data as \"validation\" so we can determine if we ever \"overfit\" the network to the training data. If the validation data, which are not used to train the data, yield a lower accuracy than the training set, we know that the model has overfit to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCA9nkvbP37-",
        "colab_type": "code",
        "outputId": "4f317182-e6dc-4cf4-f0bf-4f522509ce05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 11s - loss: 0.2454 - acc: 0.9251 - val_loss: 0.1020 - val_acc: 0.9684\n",
            "Epoch 2/5\n",
            " - 10s - loss: 0.1038 - acc: 0.9683 - val_loss: 0.0774 - val_acc: 0.9759\n",
            "Epoch 3/5\n",
            " - 9s - loss: 0.0722 - acc: 0.9772 - val_loss: 0.0674 - val_acc: 0.9776\n",
            "Epoch 4/5\n",
            " - 9s - loss: 0.0570 - acc: 0.9818 - val_loss: 0.0730 - val_acc: 0.9776\n",
            "Epoch 5/5\n",
            " - 10s - loss: 0.0458 - acc: 0.9849 - val_loss: 0.0643 - val_acc: 0.9815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAs7hx9kQlJk",
        "colab_type": "text"
      },
      "source": [
        "We can easily evaluate the performance of the model as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj0BYMRhQoMD",
        "colab_type": "code",
        "outputId": "6758ddae-a13c-4945-ffab-2f95acb7b49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.06425150974661228\n",
            "Test accuracy: 0.9815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_MdCYIhSHxq",
        "colab_type": "text"
      },
      "source": [
        "Pretty good accuracy, right?\n",
        "\n",
        "Can we do even better?\n",
        "\n",
        "Yes we can, using convolutional neural networks (CNNs) (see workshop lecture). Let's build a simple CNN for this problem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQvV-1cSSqNk",
        "colab_type": "code",
        "outputId": "3eac5892-179f-4d3e-f7d4-41ed0058c4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGsV1kNDS2Yc",
        "colab_type": "text"
      },
      "source": [
        "Before we retrain, we have to reshape our data to be able to be input into a CNN, which can take an entire matrix (or series of matrices in the case of RGB color images) as input:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL5oR_t-TTzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPbS-HEbUgyz",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 6:** Evaluate the performance of the CNN. Does it perform better than the MLP network? Does it overfit? Hint: you may need to train the network for a few more epochs in order for the performance to converge to its optimum. This waiting is a natural part of the machine learning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv9MsQgMS6jW",
        "colab_type": "code",
        "outputId": "439dc15c-fc67-4061-e5d1-453b7a50ef50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "# (just to verify)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, y_test))\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-f8db712349ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u0gyHw4Uyvm",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 7 (challenge):** Try different neural network architectures as you see fit. Also try different parameters to feed into the network (these are called \"hyperparameters\"). Can you build a network that performs better than one of the two that we provided? Can you automate the process of finding the optimal parameteres for the neural network using a series of nested for loops?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jm_p05MRglY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhw0J2mVlMH",
        "colab_type": "text"
      },
      "source": [
        "# Part 3: Parting Words and Common Pitfalls\n",
        "\n",
        "Congrats! You were able to make machines learn using a variety of different methods in a very short period of time. Great work!\n",
        "\n",
        "We note that at the end of the day, \"machine learning\" is just automated complex (and sometimes, simple) statistics. We leave you with a list of common pitfalls in machine learning:\n",
        "\n",
        "1. **Unbalanced datasets:** It is important for you to have an equal number of data points representing each class in both your training and testing datasets. To illustrate this point, imagine if your classifier is supposed to predict \"0\" or \"1\" for having a disease but always predicts \"0\". What would the performance of the network be reported as if the testing set only contained examples labeled as \"0\"? You can mitigate this problem by either upsampling or downsampling the datasets.\n",
        "2. **Overfitting:** If you train your models with data that is not representative of the entire space of possible inputs, the model will not generalize when trying to predict new data that do not resemble the training data. This can also happen if you train your neural network for too many epochs.\n",
        "3. **Ineffective evaluation metrics:** Accuracy is one performance of success of models, but it does not correctly distinguish true positive rates and false positive rates. See the table on the righthand side of [this Wikipedia article](https://en.wikipedia.org/wiki/Confusion_matrix) to see all of the common machine learning metrics used. \n",
        "\n",
        "Cheers,\n",
        "\n",
        "p"
      ]
    }
  ]
}